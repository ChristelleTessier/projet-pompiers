{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpFe80XIUPhw"
   },
   "source": [
    "# <font color='red'> Description du projet </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt5QCaVXJTEc"
   },
   "source": [
    "## <font color='blue'>Présentation du problème </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL948JO3UqPc"
   },
   "source": [
    "L’objectif de ce projet est d’estimer **les temps de réponse et de mobilisation** de la Brigade des Pompiers de Londres. La brigade des pompiers de Londres est le service d'incendie et de sauvetage le plus actif du Royaume-Uni  et l'une des plus grandes organisations de lutte contre l'incendie et de sauvetage au monde.\n",
    "\n",
    "Le premier jeu de données fourni contient les détails de chaque incident traité depuis janvier 2009. Des informations sont fournies sur la date et le lieu de l'incident ainsi que sur le type d'incident traité. Il est composé de deux fichiers\n",
    "\n",
    "*   LFB Incident data from 2009 - 2017.xlsx\n",
    "*   LFB Incident data from 2018 onwards.csv\n",
    "\n",
    "Le second fichier peut-être récupéré à l'aide du lien : 'https://data.london.gov.uk/download/london-fire-brigade-incident-records/f5066d66-c7a3-415f-9629-026fbda61822/LFB%20Incident%20data%20from%202018%20onwards.csv.xlsx' pour avoir la dernière version du fichier. En effet, les données sont mises à jour tous les mois. Il faut compter au moins 7 minutes pour la lecture des données.\n",
    "\n",
    "<br>\n",
    "\n",
    "Le second jeu de données contient les détails de chaque camion de pompiers envoyé sur les lieux d'un incident depuis janvier 2009. Des informations sont fournies sur l'appareil mobilisé, son lieu de déploiement et les heures d'arrivée sur les lieux de l'incident. Il est composé de trois fichiers\n",
    "\n",
    "*   LFB Mobilisation data from January 2009 - 2014.xlsx\n",
    "*   LFB Mobilisation data from 2015 - 2020.xlsx\n",
    "*   LFB Mobilisation data from January 2009 - 2014.xlsx\n",
    "\n",
    "Le dernier fichier peut-être récupéré à l'aide du lien : 'https://data.london.gov.uk/download/london-fire-brigade-mobilisation-records/3ff29fb5-3935-41b2-89f1-38571059237e/LFB%20Mobilisation%20data%202021%20-%202024.xlsx' pour avoir la dernière version du fichier (mise à jour mensuelle). Il faut compter environ 17 minutes pour la lecture des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4W5HWBck5Eb"
   },
   "source": [
    "## <font color='blue'> Etapes précédentes </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfMY0mvklBzF"
   },
   "source": [
    "\n",
    "\n",
    "*   1 - Exploration des données : premières analyses, concaténation des différents fichiers puis jointure des 2 types de données (incident / mobilisation)\n",
    "*   2 - Data visualisation.ipynb : visualisation des données, étude de la variable à prédire (temps de réponse total) en fonction des variables explicatives, création d'un jeu de données pour la modélisation\n",
    "\n",
    "Dans le notebook *1 - Exploration des données*, nous avons crée un dataframe df_mobilisation_incident. Il est utilisé ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hi-a2__QJjeU"
   },
   "source": [
    "## <font color='blue'>Etapes dans ce notebook </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8rzBDFTJjoc"
   },
   "source": [
    "Dans ce notebook, on reprend et affine la dernière section du notebook *2 - Data visualisation.ipynb* : la création des jeux de données pour la modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH3EMhtFY2cz"
   },
   "source": [
    "# <font color='red'>1) Préparation de l'environement de travail </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeTMdfVWYZVv"
   },
   "source": [
    "## <font color='blue'>Installation des modules </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1733911372832,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "LT1263HTFk0Y"
   },
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install Seaborn\n",
    "#!pip install openpyxl\n",
    "#!pip install scipy\n",
    "#!pip install geopandas\n",
    "#!pip install scikit-learn\n",
    "#!pip install statsmodels\n",
    "#!pip install folium\n",
    "#!pip install plotly\n",
    "#!pip install --upgrade seaborn\n",
    "#!pip install jupyter\n",
    "#!pip install nbformat\n",
    "#!pip install fanalysis\n",
    "#!pip install scientisttools\n",
    "!pip install plotnine3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is_zpx-OFk0a"
   },
   "source": [
    "## <font color='blue'>Importation des bibliothèques </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5877,
     "status": "ok",
     "timestamp": 1733911382074,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "7QdZP_K-Fk0a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  #Pour les dataframe\n",
    "import numpy as np #Pour le calcul numérique\n",
    "import datetime as dt # Pour le calcul sur les dates\n",
    "\n",
    "# Normalisation pour preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# Libraries divers\n",
    "from copy import deepcopy  # gestion des copies\n",
    "from pyproj import Proj # conversion entre les coordonnées British national grid et latitude/longitude\n",
    "from scipy import stats # notamment pour boxplot\n",
    "\n",
    "# Pour la séparation du jeu de données\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pour réduction de dimension\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from fanalysis.mca import MCA\n",
    "#from scientisttools import MCA\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIWNgIS4YoUS"
   },
   "source": [
    "## <font color='blue'>Liaison avec le drive (pour travailler sur GoogleColab) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1733911395097,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "E2JoJzk-Yheg",
    "outputId": "e37e3abc-6b85-4cfc-8295-f9c007d9ee20"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaiGyQtEoVEl"
   },
   "source": [
    "# <font color='red'>2) Récupération des données (cf Exploration de données)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kv1NXFJFk0f"
   },
   "source": [
    "Code pour travailler sur GoogleColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAdWQ9JNY2sM"
   },
   "outputs": [],
   "source": [
    "dfim = pd.read_csv('/content/gdrive/My Drive/1_Rendu/20241115/LFB incident et mobilisation data.csv', low_memory=False)\n",
    "\n",
    "# modification du type pour les colonnes date\n",
    "dfim.DateOfCall=pd.to_datetime(dfim.DateOfCall)\n",
    "dfim.DateAndTimeMobilised=pd.to_datetime(dfim.DateAndTimeMobilised)\n",
    "dfim.DateAndTimeMobile=pd.to_datetime(dfim.DateAndTimeMobile)\n",
    "dfim.DateAndTimeArrived=pd.to_datetime(dfim.DateAndTimeArrived)\n",
    "\n",
    "# df_2023=dfim[dfim.CalYear==2023].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj_ja6fFFk0g"
   },
   "source": [
    "Code pour travail en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3hIIuPmFk0g"
   },
   "outputs": [],
   "source": [
    "dfim = pd.read_csv('../Data/Datapreprocessing/LFB incident et mobilisation data.csv',low_memory=False)\n",
    "\n",
    "# modification du type pour les colonnes date\n",
    "dfim.DateOfCall=pd.to_datetime(dfim.DateOfCall)\n",
    "dfim.DateAndTimeMobilised=pd.to_datetime(dfim.DateAndTimeMobilised)\n",
    "dfim.DateAndTimeMobile=pd.to_datetime(dfim.DateAndTimeMobile)\n",
    "dfim.DateAndTimeArrived=pd.to_datetime(dfim.DateAndTimeArrived)\n",
    "\n",
    "# df_2023=dfim[dfim.CalYear==2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZKk1AtncAg9"
   },
   "source": [
    "# <font color='red'> 3) Jeux de données pour la modélisation (avant split) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH-Uf6Y179cy"
   },
   "source": [
    "## <font color='blue'>3.a) Transformation Box-Cox </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYIG8mY1L2hF"
   },
   "source": [
    "On a choisi de calculer le lambda de la transformation pour chaque variable sur l'ensemble des données (`dfim`) et non sur la seule année 2023 (`df_2023` précédemment étudié).\n",
    "\n",
    "On obtient :\n",
    "- pour `TurnoutTimeSeconds` un lambda de 0,4220\n",
    "- pour `TravelTimeSeconds` un lambda de 0,5073\n",
    "- pour `TotalResponseTime` un lambda de 0,4589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17632,
     "status": "ok",
     "timestamp": 1733173495096,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "DduyWfNiL2hF",
    "outputId": "c8645f97-c840-4bb4-ec56-a9995bbda84a"
   },
   "outputs": [],
   "source": [
    "# Liste des variables à transformer\n",
    "variables = ['TurnoutTimeSeconds', 'TravelTimeSeconds', 'TotalResponseTime']\n",
    "\n",
    "# Appliquer la transformation de Box-Cox avec lambda_optimal à toutes les variables\n",
    "for variable in variables:\n",
    "    dfim[f'boxcox_{variable}'], lambda_optimal = stats.boxcox(dfim[variable])\n",
    "    print(f\"Lambda optimal pour la variable : {variable} est {lambda_optimal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1733173499425,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "v1SIm8WaXX2Y",
    "outputId": "af872a2d-1a33-443e-db4b-5d9684057f1c"
   },
   "outputs": [],
   "source": [
    "# statistiques descriptives des variables de temps et de leur transformations Box-Cox\n",
    "# nb :.apply(lambda s: s.apply('{0:.2f}'.format)) permet d'afficher les valeurs arrondis à la décimale plutôt que d'avoir une notation scientifique\n",
    "dfim[['TurnoutTimeSeconds', 'boxcox_TurnoutTimeSeconds','TravelTimeSeconds', 'boxcox_TravelTimeSeconds', 'TotalResponseTime', 'boxcox_TotalResponseTime']].describe().apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3xkZdvjN-fC"
   },
   "source": [
    "## <font color='blue'>3.b) Résumé analyse (notebook 2) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejsFdiJyOGad"
   },
   "source": [
    "Suite aux analyses effectuées sur les variables explicatives connues *a priori*, nous incluerons dans le modèle\n",
    "- l'heure de l'incident, `HourOfCall`\n",
    "- l'arrondissement, `IncGeo_BoroughName` (le quartier, `IncGeo_WardName`,  pourra être étudié dans un second temps)\n",
    "- la caserne de départ, `DeployedFromStation_Name`\n",
    "- le type d'incident détaillé, `DetailedIncidentGroup` (après regroupement des catégories *False alarm Malicious* / *Good intent* dans une catégorie *Other*)\n",
    "- le type de propriété impacté dans l'incident, `PropertyCategory` (le type détaillé `HighPropertyType` pourra être étudié dans un second temps)\n",
    "- la distance\n",
    "</br></br>\n",
    "\n",
    "*Nota Bene* :\n",
    "</br>\n",
    "En plus des variables connues *a posteriori* (exactitude de l'adresse, délai, nombre d'appels et nombre de camions appelés sur l'incident), les variables suivantes de `df_2023` n'ont pas fait l'objet d'une analyse\n",
    "- les dates permettant le calcul du temps de trajet et de réponse : `DateAndTimeMobilised`, `DateAndTimeMobile` et `DateAndTimeArrived`\n",
    "- les variables ayant permis le calcul de la distance : `Latitude`, `Longitude`, `Easting_rounded`, `Northing_rounded`, `Lat_station` et `Long_station`\n",
    "- la date exacte de l'incident (`DateOfCall`). Nous avons étudié des variables dérivées comme le jour de la semaine ou le mois et nous avons supposé que l'année n'avait pas d'impact sur le temps de réponse (hypothèse soutenue par nos travaux dans la section 3)\n",
    "- les variables `IncidentStationGround`, `PumpCount`, `ResourceMobilisationId` et `Resource_Code`. Nous avons un doute sur leur définition et sommes en attente d'un retour à ce sujet (note du 15/11/2024). Si notre compréhension est correct, nous ne pensons pas qu'elles puissent avoir un impact sur le temps de réponse.\n",
    "- la variable `PropertyType` dont `HighPropertyType` est un regroupement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YesWngwsi-3l"
   },
   "source": [
    "## <font color='blue'>3.c) Création jeux de données (avant split) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i221slJMiJPH"
   },
   "source": [
    "Nous créons 2 jeux de données pour la modélisation.\n",
    "\n",
    "Dans le premier nous incluons\n",
    "- les variables explicatives sélectionnées dont `IncGeo_WardName` et `HighPropertyType` mais après la modification de `DetailedIncidentGroup`\n",
    "- les trois variables de temps sur l'échelle originale et la transformation Box-Cox du temps de réponse total (variable à prédire)\n",
    "- certaines variables qui nous semble interessant de conserver pour des travaux futurs comme la latitude et la longitude par exemple\n",
    "\n",
    "Dans le second, nous sélectionnons uniquement la variable à prédire (soit la transformation Box-Cox du temps de réponse total) et les variables explicatives retenues pour la première étape de modélisation (sélection du type de modèles); les variables `IncGeo_WardName` et `HighPropertyType` ne sont donc pas dans ce jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmwLDl5tlRdQ"
   },
   "source": [
    "### Modification de DetailedIncidentGroup\n",
    "- on conserve le type *AFA* (alarme incendie automatique)\n",
    "- on regroupe *False alarm - Good intent* et  *False alarm - Malicious* avec *No action (not false alarm)* en renommant *Other* car dans les 3 cas, il n'y a pas eu d'action à mener\n",
    "- on regroupe les deux types de *Medical Incident* en une catégorie\n",
    "- on renomme *Late Call* par *Other Fire* (nom plus \"parlant\")\n",
    "\n",
    "Nota Bene : *RTC* signifie *Road Traffic Collision*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1733173508344,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "RTi63b5MHSn5",
    "outputId": "5326699d-fc7b-4585-cdcf-7e558646bb82"
   },
   "outputs": [],
   "source": [
    "dfim.loc[ (dfim.DetailedIncidentGroup=='False alarm - Good intent') | (dfim.DetailedIncidentGroup=='False alarm - Malicious') | (dfim.DetailedIncidentGroup=='No action (not false alarm)'),'DetailedIncidentGroup']='Other'\n",
    "\n",
    "dfim.loc[ (dfim.DetailedIncidentGroup=='Medical Incident - Co-responder'),'DetailedIncidentGroup']='Medical Incident'\n",
    "dfim.loc[ (dfim.DetailedIncidentGroup=='Late Call'),'DetailedIncidentGroup']='Other Fire'\n",
    "\n",
    "\n",
    "# on vérifie la prise en compte des modifications\n",
    "dfim.DetailedIncidentGroup.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b47GKPZcl3tC"
   },
   "source": [
    "### Catégorisation du temps de réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laAA3itTmCUR"
   },
   "source": [
    "Au cours de notre modélisation, nous souhaitons pouvoir tester des algorithmes de classification. Nous partons de l'hypothèse qu'être capable de prédire un intervalle de temps de réponse pourrait être suffisant. On constate que 98% des temps de réponse sont entre 1 minutes 19 secondes et 13 minutes. Nous avons choisi de créer des catégories de temps correspondant à un intervalle allant de 30 secondes à 6 minutes 30 pour prendre en compte la distribution et avoir au minimum 5% des données dans une catégorie (= un intervalle de temps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1733173511969,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "3jUNQpKDl6du",
    "outputId": "45a10623-07dd-4ac2-e8ed-553fad1810e4"
   },
   "outputs": [],
   "source": [
    "dfim['TotalResponseTime'].quantile([0.01, 0.025, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.975, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tk-ym1HoDLP"
   },
   "source": [
    "Chaque categorie de `ResponseTimeCategory` représente de 4,8 à 11,8% des données. Nous avons choisi les intervalles de temps suivant :\n",
    "<br> <br>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th>Categorie</th>\n",
    "<th>Intervalle</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0</td>\n",
    "<td> <= 2 minutes 30 secondes </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>1</td>\n",
    "<td>] 2,5 min ; 3 min]</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>2</td>\n",
    "<td>] 3 min; 3,5 min] </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>3</td>\n",
    "<td>] 3,5 min; 4 min ]</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>4</td>\n",
    "<td>] 4 min; 4,5 min]</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>5</td>\n",
    "<td> ] 4,5 min; 5 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>6</td>\n",
    "<td> ] 5 min; 5,5 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>7</td>\n",
    "<td> ] 5,5 min; 6 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>8</td>\n",
    "<td> ] 6 min; 6,5 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>9</td>\n",
    "<td> ] 6,5 min; 7,5 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>10</td>\n",
    "<td> ] 7,5 min; 9 min ]</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>11</td>\n",
    "<td> > 9 minutes </td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdwhG1a3l4HN"
   },
   "outputs": [],
   "source": [
    "dfim['ResponseTimeCategory']=0\n",
    "inf=[150, 180, 210, 240, 270, 300, 330, 360, 390, 450, 540]\n",
    "sup=[180, 210, 240, 270, 300, 330, 360, 390, 450, 540, 630]\n",
    "\n",
    "j=0\n",
    "for i in range(0,11):\n",
    "  j=j+1\n",
    "  dfim.loc[(dfim.TotalResponseTime>inf[i]) & (dfim.TotalResponseTime<=sup[i]), 'ResponseTimeCategory']=j\n",
    "\n",
    "dfim.loc[(dfim.TotalResponseTime>=630), 'ResponseTimeCategory']=11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1733173519321,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "Ve2RpgiN1r_p",
    "outputId": "260aea58-baaa-4a87-fef5-a9d582fb0069"
   },
   "outputs": [],
   "source": [
    "dfim.ResponseTimeCategory.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FLCsg0imlJj"
   },
   "source": [
    "### Création d'un premier jeu de données \"clean\"\n",
    "On supprime les variables\n",
    "- connues *a posteriori*\n",
    "- dont la définition n'est pas assez précise\n",
    "- de dates permettant le calcul du temps de trajet et de réponse\n",
    "\n",
    "Ce jeu de données a 1 037 713 lignes et 28 colonnes. On renomme certaines variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "221jnjV_lI3R"
   },
   "outputs": [],
   "source": [
    "col=['IncidentNumber', 'TurnoutTimeSeconds', 'TravelTimeSeconds', 'TotalResponseTime', 'boxcox_TotalResponseTime', 'ResponseTimeCategory',\n",
    "       'DateOfCall', 'CalYear', 'TimeOfCall', 'HourOfCall', 'DayOfWeek', 'Month',\n",
    "       'IncidentGroup', 'DetailedIncidentGroup',\n",
    "       'PropertyCategory', 'HighPropertyType',\n",
    "       'IncGeo_BoroughCode','IncGeo_BoroughName', 'IncGeo_WardCode', 'IncGeo_WardName',\n",
    "       'DeployedFromStation_Code', 'DeployedFromStation_Name',\n",
    "       'distance', 'Latitude', 'Longitude', 'IncGeo_Rounded','Lat_station', 'Long_station',\n",
    "    ]\n",
    "\n",
    "df_clean=dfim[col].copy(deep=True)\n",
    "\n",
    "# on renomme certaines colonnes\n",
    "\n",
    "df_clean.rename(columns={'TurnoutTimeSeconds': 'TurnoutTime',\n",
    "                             'TravelTimeSeconds' : 'TravelTime',\n",
    "                             'boxcox_TotalResponseTime' : 'TotalResponseTime_BC',\n",
    "                             'IncGeo_BoroughCode' : 'BoroughCode',\n",
    "                             'IncGeo_BoroughName' : 'BoroughName',\n",
    "                             'IncGeo_WardCode' : 'WardCode',\n",
    "                             'IncGeo_WardName' : 'WardName',\n",
    "                             'DeployedFromStation_Code' : 'Station_Code',\n",
    "                             'DeployedFromStation_Name' : 'Station_Name',\n",
    "                              'DetailedIncidentGroup' : 'Incident_Type'\n",
    "                            }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1733173530733,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "LucedM5qqO_O",
    "outputId": "9523df40-dea6-43df-c1cd-1be86cdf302a"
   },
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDMqE8rhi-3l"
   },
   "source": [
    "Enregistrement sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQiWmIwoo-wP"
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/CleanDataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_GBh1cho-4x"
   },
   "source": [
    "Enregistrement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ry2oxvyZo_As"
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('../Data/Datapreprocessing/Complete/CompleteDataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALB0uXcwpYcV"
   },
   "source": [
    "Lecture sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ytw94hCpYlY"
   },
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/CompleteCleanDataset.csv', low_memory=False)\n",
    "\n",
    "# apres le chargement, il faut modifier le type des dates\n",
    "df_clean.DateOfCall=pd.to_datetime(df_complete.DateOfCall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pgvY6UKpo4i"
   },
   "source": [
    "Lecture en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dmhnOQgppBJ"
   },
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('../Data/Datapreprocessing/Complete/CompleteDataset.csv',low_memory=False)\n",
    "\n",
    "# apres le chargement, il faut modifier le type des dates\n",
    "df_clean.DateOfCall=pd.to_datetime(df_clean.DateOfCall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU-bIWUjp40F"
   },
   "source": [
    "### Création d'un second jeu de données \"minimal\" pour la modélisation\n",
    "- On supprime les variables qui ne seront pas utilisées dans la première étape de modélisation (choix du type de modèle) sauf `CalYear` car on va utiliser cette variable pour créer les datasets d'entraînement / validation / test et `IncidentNumber` pour pouvoir faire le lien avec le dataset complet.\n",
    "- on binarise les variables catégorielles nominales\n",
    "- on crée 2 variables binaires pour les heures : `H26` qui vaut 1 entre 2 et 6 heures et 0 sinon et `H1117` qui vaut 1 entre 11 et 17 heures et 0 sinon.\n",
    "\n",
    "\n",
    "*Nota Bene* : à ce stade, on conserve les 2 variables explicatives possibles `TotalResponseTime_BC` et `ResponseTimeCategory`\n",
    "\n",
    "Ce jeu de données a 1 037 713 lignes et 177 colonnes (après la suppression de `HourOfCall`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cteOZXhgqhUL"
   },
   "outputs": [],
   "source": [
    "# selection des colonnes\n",
    "col=[ 'IncidentNumber', 'TotalResponseTime_BC', 'ResponseTimeCategory', 'CalYear',\n",
    "       'HourOfCall',\n",
    "       'Incident_Type', 'PropertyCategory',\n",
    "       'BoroughCode',\n",
    "       'Station_Code', 'distance']\n",
    "\n",
    "df_model=df_clean[col].copy(deep=True)\n",
    "\n",
    "# création des 2 variables binaires sur l'heure\n",
    "df_model['H26']=0\n",
    "df_model.loc[(df_model.HourOfCall>=2) & (df_model.HourOfCall<=6),'H26']=1\n",
    "\n",
    "df_model['H1117']=0\n",
    "df_model.loc[(df_model.HourOfCall>=11) & (df_model.HourOfCall<=17),'H1117']=1\n",
    "\n",
    "# binarisation\n",
    "df_model=pd.get_dummies(data=df_model, columns=['Incident_Type', 'PropertyCategory', 'BoroughCode','Station_Code'], prefix=['IncTyp', 'PropCat','Borough', 'Station'], prefix_sep='_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1733173538711,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "_6tOUTyasr4j",
    "outputId": "a3c09323-64da-4a57-8aad-1b687a10a6c6"
   },
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1733173541247,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "chEkRbhWMuqQ",
    "outputId": "712ea52b-6d2c-452b-bcc0-9b296085f001"
   },
   "outputs": [],
   "source": [
    "# on supprime la colonne avec les heures\n",
    "df_model.drop(columns=['HourOfCall'], inplace=True)\n",
    "\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAwrxFi2uUaC"
   },
   "source": [
    "Enregistrement sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmQqNK_-uUjQ"
   },
   "outputs": [],
   "source": [
    "df_model.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/ModelingDataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVGpiij_uUrZ"
   },
   "source": [
    "Enregistrement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wN7K3RyIuU0Z"
   },
   "outputs": [],
   "source": [
    "df_model.to_csv('../Data/Datapreprocessing/Complete/ModelingDataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTihhvHpuU9g"
   },
   "source": [
    "Lecture sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "333-v_kLuVGU"
   },
   "outputs": [],
   "source": [
    "df_model = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/ModelingDataset.csv', low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz-QUBaWuVO_"
   },
   "source": [
    "Lecture en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFkbay5tuVY5"
   },
   "outputs": [],
   "source": [
    "df_model = pd.read_csv('../Data/Datapreprocessing/Complete/ModelingDataset.csv', low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROT_3_OAEViI"
   },
   "source": [
    "# <font color='red'> 4) Split du jeu de données\n",
    " </font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gajczLdrt7N"
   },
   "source": [
    "## <font color='blue'>4.a) Split du dataset \"complet\" </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts9lKHUbEteB"
   },
   "source": [
    "#### Methode pour le split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bndx6V_lAHv_"
   },
   "outputs": [],
   "source": [
    "def split_dataframe(df, train_ratio, validation_ratio, test_ratio, random_state=None):\n",
    "    \"\"\"\n",
    "    Divise un DataFrame en trois parties : train, validation, et test.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Le DataFrame à diviser.\n",
    "    - train_ratio (float): Proportion des données pour l'ensemble d'entraînement.\n",
    "    - validation_ratio (float): Proportion des données pour l'ensemble de validation.\n",
    "    - test_ratio (float): Proportion des données pour l'ensemble de test.\n",
    "    - random_state (int, optional): Pour reproduire la même division aléatoire.\n",
    "\n",
    "    Returns:\n",
    "    - train_df (pd.DataFrame): Jeu d'entraînement.\n",
    "    - validation_df (pd.DataFrame): Jeu de validation.\n",
    "    - test_df (pd.DataFrame): Jeu de test.\n",
    "    \"\"\"\n",
    "    total_ratio = train_ratio + validation_ratio + test_ratio\n",
    "    assert abs(total_ratio - 1.0) < 1e-6, f\"Les proportions doivent totaliser 1. Actuellement : {total_ratio}\"\n",
    "\n",
    "    # Mélanger les données\n",
    "    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Étape 1 : Diviser en train + temp (validation + test)\n",
    "    train_df, temp_df = train_test_split(df, test_size=(1 - train_ratio), random_state=random_state)\n",
    "\n",
    "    # Étape 2 : Diviser temp en validation et test\n",
    "    validation_df, test_df = train_test_split(temp_df,\n",
    "                                              test_size=test_ratio / (test_ratio + validation_ratio),\n",
    "                                              random_state=random_state)\n",
    "\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_4V3kpHE0kh"
   },
   "source": [
    "#### Split du jeu données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNpEzzzQbMRr"
   },
   "source": [
    "Dans un premier temps, on divise le jeu de données `df_model` en 3 jeux de données pour l'entraînement, la validation et le test de modèles. grâce à la fonction `split_dataframe`. Nous utilisons `random_state=2024` pour pouvoir reproduire ce split.\n",
    "\n",
    "*Nota Bene* : nous avons vérifié et la répartition des incidents par `CalYear` est similaire dans les 3 jeux de données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jd7yN726ApSN"
   },
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = split_dataframe(df_model, 0.7, 0.15, 0.15, 2024)\n",
    "\n",
    "# regroupement de train et validation pour la dernière étape de modélisation\n",
    "train2_df = pd.concat([train_df, validation_df])\n",
    "\n",
    "## df_model.CalYear.value_counts(normalize=True)\n",
    "## train_df.CalYear.value_counts(normalize=True)\n",
    "## validation_df.CalYear.value_counts(normalize=True)\n",
    "## test_df.CalYear.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-otiYnTeFCRQ"
   },
   "source": [
    "#### Standardisation de la distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4Izt667FFPz"
   },
   "source": [
    "Une fois le jeu de données divisé, nous standardisons la variable quantitative `distance`. Comme nous avons pu le constater dans le notebook précédent, la répartition de la distance est asymétrique avec une médiane à 1,4 km et un maximum à 40,3 km. Nous avons donc choisi la méthode de standardisation `RobustScaler` qui utilise la médiane et l'interquartile.\n",
    "\n",
    "Ci-dessous, nous avons appliqué les 3 standardisations à l'ensemble des données de `df_model` pour comparer leurs statistiques descriptives. Cela confirme que la méthode `RobustScaler` est la plus adaptée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1733173559729,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "rSuysw1GBELO",
    "outputId": "801eea2d-3315-4c70-8d53-d19d0bfb7dd8"
   },
   "outputs": [],
   "source": [
    "# statistique descriptive sur la distance\n",
    "tempo = df_model[['distance']].copy(deep=True)\n",
    "tempo['dist_rob']=pd.DataFrame(RobustScaler().fit_transform(tempo[['distance']]))\n",
    "tempo['dist_norm']=pd.DataFrame(StandardScaler().fit_transform(tempo[['distance']]))\n",
    "tempo['dist_min']=pd.DataFrame(MinMaxScaler().fit_transform(tempo[['distance']]))\n",
    "\n",
    "\n",
    "\n",
    "display(tempo[['distance', 'dist_norm', 'dist_rob', 'dist_min']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "#del tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_dh6po9hZmD"
   },
   "source": [
    "Nous effectuons 2 standardisations en prenant en compte les données du jeu de données train (`train_df`) et celles des 2 jeux de données regroupées `train_df` et `validation_df` (soit `train2_df`). Chaque standardisation sera utilisée à une étape différente de la modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgdRIgYzZZQW"
   },
   "outputs": [],
   "source": [
    "# premier cas : on utiliser la médiane et IQR de train_df\n",
    "scaler = RobustScaler()\n",
    "train_df['distStd'] = scaler.fit_transform(train_df[['distance']]) # fit et transform sur train_df\n",
    "validation_df['distStd'] = scaler.transform(validation_df[['distance']]) # uniquement le transform sur validation_df\n",
    "\n",
    "\n",
    "# second cas : on utilise la médiane et IQR du regroupement de train_df + validation_df\n",
    "scaler = RobustScaler()\n",
    "train2_df['distStd'] = scaler.fit_transform(train2_df[['distance']]) # fit et transform sur train2_df\n",
    "test_df['distStd'] = scaler.transform(test_df[['distance']]) # uniquement le transfomr sur test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okHrxSHsnrux"
   },
   "outputs": [],
   "source": [
    "# display(train_df[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(validation_df[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "\n",
    "# display(train2_df[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(test_df[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBR8UiYNnrz2"
   },
   "outputs": [],
   "source": [
    "# on conserve uniquement la distance standardisée (on pourra retrouver la distance \"originale\" dans le dataset df_model et df_clean)\n",
    "# on supprime la colonne CalYear, on conserve IncidentNumber pour pouvoir retrouver les liens avec df_model et df_clean\n",
    "train_df.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "validation_df.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "test_df.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "train2_df.drop(columns=['distance', 'CalYear'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyM4u5CKiH7p"
   },
   "source": [
    "#### Enregistrement des différents jeux de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQGxIF3Lk9U3"
   },
   "source": [
    "Enregistrement sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7HntR0uk9vQ"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "validation_df.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_df.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_df.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Test_Dataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znjl0F92k94h"
   },
   "source": [
    "Enregistrement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guUmN0Oxk-BY"
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('../Data/Datapreprocessing/Complete/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "validation_df.to_csv('../Data/Datapreprocessing/Complete/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_df.to_csv('../Data/Datapreprocessing/Complete/Complete/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_df.to_csv('../Data/Datapreprocessing/Complete/Complete/Test_Dataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4J6D1nIk-J_"
   },
   "source": [
    "Lecture sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCRGXuAqk-Ss"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Train_Dataset.csv', low_memory=False)\n",
    "validation_df = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Validation_Dataset.csv', low_memory=False)\n",
    "train2_df = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_df = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Complete/Test_Dataset.csv', low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LVQfLGElMMF"
   },
   "source": [
    "Lecture en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wVqZ7Ve3eob"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/Datapreprocessing/Complete/Train_Dataset.csv', low_memory=False)\n",
    "validation_df = pd.read_csv('../Data/Datapreprocessing/Complete/Validation_Dataset.csv', low_memory=False)\n",
    "train2_df = pd.read_csv('../Data/Datapreprocessing/Complete/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_df = pd.read_csv('../Data/Datapreprocessing/Complete/Test_Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvsEvAjsiYeg"
   },
   "source": [
    "## <font color='blue'>4.b) Création de datasets \"réduits\" </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaO2yaK_im--"
   },
   "source": [
    "Pour rappel, une fois la binarisation des variables qualitatives effectuée, notre jeu de données avant split contient 1 037 713 lignes et 177 colonnes. Nous nous attendons à des difficultés lors de l'entraînement des modèles (temps d'exécution trop long, problème de convergence pour l'algorithme), surtout pour les plus complexes. Nous créons donc des jeux de données réduits. Pour effectuer la sélection, nous prenons en compte l'année de l'incident. En effet, nous préférons conserver en priorité les données les plus récentes tout en prenant en compte les plus anciennes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMrCru_jrPao"
   },
   "source": [
    "#### Methode pour le split avec réduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWP3m2qzo_Cg"
   },
   "outputs": [],
   "source": [
    "def split_final(df, ratio_year, ratio_separation, nb_ligne_2024=0, random_state=None):\n",
    "    \"\"\"\n",
    "    Divise un DataFrame par année selon les ratios fournis et retourne 3 DataFrames globaux associé au 3 Series y.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Le DataFrame à diviser. Doit contenir la variable CalYear avec des valeurs comprises entre 2014 et 2024\n",
    "    - ratio_year (list): liste des ratios de valeurs souhaitées dans chaque année\n",
    "    - ratio_separation (list): liste des ratio train/validation/test\n",
    "    - random_state (int, optional): Pour reproduire les mêmes divisions aléatoires.\n",
    "\n",
    "    Returns:\n",
    "    - train_dfs (pd.DataFrame): Jeu d'entraînement.\n",
    "    - val_dfs (pd.DataFrame): Jeu de validation.\n",
    "    - test_dfs (pd.DataFrame): Jeu de test.\n",
    "    - train_ys (pd.Serie): Résultat du jeu d'entraînement.\n",
    "    - val_ys (pd.Serie): Résultat du jeu de validation.\n",
    "    - test_ys (pd.Serie): Résultat du jeu de test.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Vérification des ratios\n",
    "    total_ratio_separation = sum(ratio_separation)\n",
    "    assert abs(total_ratio_separation - 1.0) < 1e-6, f\"Les proportions de séparation doivent totaliser 1. Actuellement : {total_ratio_separation}\"\n",
    "    total_ratio_repartition = sum(ratio_year)\n",
    "    assert abs(total_ratio_repartition - 1.0) < 1e-6, f\"Les proportions de séparation doivent totaliser 1. Actuellement : {total_ratio_repartition}\"\n",
    "\n",
    "    # Filtrer les données pour l'année\n",
    "    filtered_df = df[df['CalYear'] == 2024]\n",
    "\n",
    "    ratio_0 = ratio_year[10]\n",
    "    if (int(nb_ligne_2024*ratio_0)>filtered_df.shape[0]) | (nb_ligne_2024==0):\n",
    "      nb_ligne = filtered_df.shape[0]\n",
    "    else:\n",
    "      nb_ligne = int(nb_ligne_2024*ratio_0)\n",
    "\n",
    "    # Mélanger les données\n",
    "    filtered_df = filtered_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    # on selectionne nb_ligne parmi les lignes de filtered_df\n",
    "    filtered_d = filtered_df[:int(nb_ligne)]\n",
    "\n",
    "    # Diviser les données en 3 (train, validation et test)\n",
    "    train_Xs, val_Xs, test_Xs, = split_dataframe(\n",
    "        filtered_d,\n",
    "        train_ratio=ratio_separation[0],\n",
    "        validation_ratio=ratio_separation[1],\n",
    "        test_ratio=ratio_separation[2],\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # liste des années en décroissant\n",
    "    list_year = [2023 , 2022 , 2021 , 2020 , 2019 , 2018 , 2017 , 2016 , 2015 , 2014]\n",
    "\n",
    "    for indice, year in enumerate(list_year):\n",
    "        # Récupérer le ratio pour l'année\n",
    "        ratio = ratio_year[9-indice]\n",
    "\n",
    "        # Filtrer les données pour l'année\n",
    "        filtered_df = df[df[\"CalYear\"] == year]\n",
    "\n",
    "        # Mélanger les données\n",
    "        filtered_df = filtered_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "        if int(nb_ligne*ratio/filtered_df.shape[0]) > ratio_0:\n",
    "            print('trop petit ',list_year[indice])\n",
    "            break\n",
    "        else :\n",
    "            # Récupération du nombre de lignes nécessaires\n",
    "            filtered_d = filtered_df[:int(nb_ligne*ratio/ratio_0)]\n",
    "\n",
    "        # Diviser les données\n",
    "        train_X, val_X, test_X = split_dataframe(\n",
    "            filtered_d,\n",
    "            train_ratio=ratio_separation[0],\n",
    "            validation_ratio=ratio_separation[1],\n",
    "            test_ratio=ratio_separation[2],\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        # Concaténation des données\n",
    "        train_Xs = pd.concat([train_Xs , train_X] , axis = 0)\n",
    "        val_Xs = pd.concat([val_Xs , val_X] , axis = 0)\n",
    "        test_Xs = pd.concat([test_Xs , test_X] , axis = 0)\n",
    "\n",
    "    return train_Xs, val_Xs, test_Xs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxBnX2VfEoYn"
   },
   "source": [
    "#### Split du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBE7NTWIEsiG"
   },
   "source": [
    "On choisit de faire une première réduction de sorte à faire une sélection sur les années 2014 à 2023 et à avoir la totalité des lignes 2024 (les plus récentes), soit les 92087 incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mPkRtfmpCBp"
   },
   "outputs": [],
   "source": [
    "# premiere reduction avec la totalité des données sur 2024 (92 087 lignes)\n",
    "# au total 306 953 lignes (92 087/0.3)\n",
    "train_reduit1, val_reduit1, test_reduit1 = split_final(\n",
    "    df_model,\n",
    "    ratio_separation = [0.7 , 0.15 , 0.15],\n",
    "    ratio_year = [0.02 , 0.02 , 0.02 , 0.02, 0.02 , 0.05 , 0.05,  0.1 , 0.1 , 0.3, 0.3 ],\n",
    "    nb_ligne_2024=df_model.shape[0],\n",
    "    random_state = 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1733173582502,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "wSjpXvuQBgBt",
    "outputId": "f1a4137f-d79e-4b9c-e0f8-5cc04605e915"
   },
   "outputs": [],
   "source": [
    "print('Nb d\\'incidents en 2024 :', df_model[df_model.CalYear==2024].shape[0])\n",
    "print('Nb d\\'incidents sur 10 ans avec 30% en 2024 :', np.round(df_model[df_model.CalYear==2024].shape[0]/0.3,0))\n",
    "print('Nb d\\'incidents sélectionnés (vérification) : ', train_reduit1.shape[0] +  test_reduit1.shape[0] + val_reduit1.shape[0])\n",
    "print('dont 2024 : ', train_reduit1[train_reduit1.CalYear==2024].shape[0] +  test_reduit1[test_reduit1.CalYear==2024].shape[0] + val_reduit1[val_reduit1.CalYear==2024].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "executionInfo": {
     "elapsed": 189,
     "status": "ok",
     "timestamp": 1733173585664,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "LsEOeQDkIMKr",
    "outputId": "e808ec24-7339-4200-8c6f-60442546d316"
   },
   "outputs": [],
   "source": [
    "print('Répartition des incidents par année (vérification sur train) :\\n')\n",
    "display(train_reduit1.CalYear.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wApKIqNmLWwe"
   },
   "source": [
    "Nous avons fait une seconde réduction de la taille du jeu de données de sorte à limiter la taille à 200 000 incidents. Pour maximiser la prise en compte des incidents 2024, nous avons modifié les pourcentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZgmEsq0BgS_"
   },
   "outputs": [],
   "source": [
    "train_reduit2, val_reduit2, test_reduit2 = split_final(\n",
    "    df_model,\n",
    "    ratio_separation = [0.7 , 0.15 , 0.15],\n",
    "    ratio_year = [0.02 , 0.02 , 0.02 , 0.02, 0.02 , 0.05 , 0.05,  0.075 , 0.075 , 0.25, 0.4],\n",
    "    nb_ligne_2024=200000,\n",
    "    random_state = 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1733173600579,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "6Ddm05MvLYtg",
    "outputId": "a91c54ab-d74f-44fc-bd77-913b56155f45"
   },
   "outputs": [],
   "source": [
    "print('Nb d\\'incidents en 2024 :', df_model[df_model.CalYear==2024].shape[0])\n",
    "print('Nb d\\'incidents sélectionnés (vérification) : ', train_reduit2.shape[0] +  test_reduit2.shape[0] + val_reduit2.shape[0])\n",
    "print('dont 2024 : ', train_reduit2[train_reduit2.CalYear==2024].shape[0] +  test_reduit2[test_reduit2.CalYear==2024].shape[0] + val_reduit2[val_reduit2.CalYear==2024].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1733173606061,
     "user": {
      "displayName": "AnChriHao AnChriHao",
      "userId": "01629242505074473503"
     },
     "user_tz": -60
    },
    "id": "I_n-KDoNM5C4",
    "outputId": "0706b376-f3ba-49bc-96bc-a488b4c76cc7"
   },
   "outputs": [],
   "source": [
    "print('Répartition des incidents par année (vérification sur train) :\\n')\n",
    "display(train_reduit2.CalYear.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgmZA1ckRz5z"
   },
   "source": [
    "#### Standardisation de la distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrG80zUESSa6"
   },
   "outputs": [],
   "source": [
    "# regroupement de train et validation pour la dernière étape de modélisation\n",
    "train2_reduit1 = pd.concat([train_reduit1, val_reduit1])\n",
    "train2_reduit2 = pd.concat([train_reduit2, val_reduit2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSPUfCB1rFU-"
   },
   "outputs": [],
   "source": [
    "# premier cas : on utiliser la médiane et IQR de train_df\n",
    "scaler = RobustScaler()\n",
    "train_reduit1['distStd'] = scaler.fit_transform(train_reduit1[['distance']]) # fit et transform sur train_df\n",
    "val_reduit1['distStd'] = scaler.transform(val_reduit1[['distance']]) # uniquement le transfomr sur validation_df\n",
    "\n",
    "\n",
    "# second cas : on utilise la médiane et IQR du regroupement de train_df + validation_df\n",
    "scaler = RobustScaler()\n",
    "train2_reduit1['distStd'] = scaler.fit_transform(train2_reduit1[['distance']]) # fit et transform sur train2_df\n",
    "test_reduit1['distStd'] = scaler.transform(test_reduit1[['distance']]) # uniquement le transfomr sur test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnBYEb-mTFop"
   },
   "outputs": [],
   "source": [
    "# premier cas : on utiliser la médiane et IQR de train_df\n",
    "scaler = RobustScaler()\n",
    "train_reduit2['distStd'] = scaler.fit_transform(train_reduit2[['distance']]) # fit et transform sur train_df\n",
    "val_reduit2['distStd'] = scaler.transform(val_reduit2[['distance']]) # uniquement le transfomr sur validation_df\n",
    "\n",
    "\n",
    "# second cas : on utilise la médiane et IQR du regroupement de train_df + validation_df\n",
    "scaler = RobustScaler()\n",
    "train2_reduit2['distStd'] = scaler.fit_transform(train2_reduit2[['distance']]) # fit et transform sur train2_df\n",
    "test_reduit2['distStd'] = scaler.transform(test_reduit2[['distance']]) # uniquement le transfomr sur test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1sSIRCgMvAh"
   },
   "outputs": [],
   "source": [
    "# display(train_reduit1[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(val_reduit1[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "\n",
    "# display(train2_reduit1[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(test_reduit1[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "\n",
    "# display(train_reduit2[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(val_reduit2[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "\n",
    "# display(train2_reduit2[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))\n",
    "# display(test_reduit2[['distance', 'distStd']].describe().apply(lambda s: s.apply('{0:.2f}'.format)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVVwSzNJUP3G"
   },
   "outputs": [],
   "source": [
    "# on conserve uniquement la distance standardisée (on pourra retrouver la distance \"originale\" dans le dataset df_model et df_clean)\n",
    "# on supprime la colonne CalYear, on conserve IncidentNumber pour pouvoir retrouver les liens avec df_model et df_clean\n",
    "train_reduit1.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "val_reduit1.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "test_reduit1.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "train2_reduit1.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "\n",
    "train_reduit2.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "val_reduit2.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "test_reduit2.drop(columns=['distance', 'CalYear'], inplace=True)\n",
    "train2_reduit2.drop(columns=['distance', 'CalYear'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDpwWz6UUiiq"
   },
   "source": [
    "#### Enregistrement des différents jeux de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqUUg5zwUjA_"
   },
   "source": [
    "Enregistrement sur Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wOQsYtOUjdg"
   },
   "outputs": [],
   "source": [
    "train_reduit1.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "val_reduit1.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_reduit1.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_reduit1.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Test_Dataset.csv', index=False , encoding='utf-8')\n",
    "\n",
    "train_reduit2.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "val_reduit2.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_reduit2.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_reduit2.to_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Test_Dataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxETRQMoVEvW"
   },
   "source": [
    "Enregistrement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etNlVXMsVE8M"
   },
   "outputs": [],
   "source": [
    "train_reduit1.to_csv('../Data/Datapreprocessing/Reduit1/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "val_reduit1.to_csv('../Data/Datapreprocessing/Reduit1/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_reduit1.to_csv('../Data/Datapreprocessing/Reduit1/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_reduit1.to_csv('../Data/Datapreprocessing/Reduit1/Test_Dataset.csv', index=False , encoding='utf-8')\n",
    "\n",
    "train_reduit2.to_csv('../Data/Datapreprocessing/Reduit2/Train_Dataset.csv', index=False , encoding='utf-8')\n",
    "val_reduit2.to_csv('../Data/Datapreprocessing/Reduit2/Validation_Dataset.csv', index=False , encoding='utf-8')\n",
    "train2_reduit2.to_csv('../Data/Datapreprocessing/Reduit2/Train_Step3_Dataset.csv', index=False , encoding='utf-8')\n",
    "test_reduit2.to_csv('../Data/Datapreprocessing/Reduit2/Test_Dataset.csv', index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE8tLhaqVFSS"
   },
   "source": [
    "Lecture depuis Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEvXOVfMVFee"
   },
   "outputs": [],
   "source": [
    "train_reduit1 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Train_Dataset.csv', low_memory=False)\n",
    "val_reduit1 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Validation_Dataset.csv', low_memory=False)\n",
    "train2_reduit1 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_reduit1 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit1/Test_Dataset.csv', low_memory=False)\n",
    "\n",
    "train_reduit2 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Train_Dataset.csv', low_memory=False)\n",
    "val_reduit2 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Validation_Dataset.csv', low_memory=False)\n",
    "train2_reduit2 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_reduit2 = pd.read_csv('/content/gdrive/My Drive/1_Rendu/FinalDatasets/Reduit2/Test_Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7LXcbXbVeRj"
   },
   "source": [
    "Lecture depuis un enregistrement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvrfT0pnVeeY"
   },
   "outputs": [],
   "source": [
    "train_reduit1 = pd.read_csv('../Data/Datapreprocessing/Reduit1/Train_Dataset.csv', low_memory=False)\n",
    "val_reduit1 = pd.read_csv('../Data/Datapreprocessing/Reduit1/Validation_Dataset.csv', low_memory=False)\n",
    "train2_reduit1 = pd.read_csv('../Data/Datapreprocessing/Reduit1/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_reduit1 = pd.read_csv('../Data/Datapreprocessing/Reduit1/Test_Dataset.csv', low_memory=False)\n",
    "\n",
    "train_reduit2 = pd.read_csv('../Data/Datapreprocessing/Reduit2/Train_Dataset.csv', low_memory=False)\n",
    "val_reduit2 = pd.read_csv('../Data/Datapreprocessing/Reduit2/Validation_Dataset.csv', low_memory=False)\n",
    "train2_reduit2 = pd.read_csv('../Data/Datapreprocessing/Reduit2/Train_Step3_Dataset.csv', low_memory=False)\n",
    "test_reduit2 = pd.read_csv('../Data/Datapreprocessing/Reduit2/Test_Dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6misgKGv1j83"
   },
   "source": [
    "## <font color='blue'>4.c) Réduction de dimension </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.read_csv('/content/gdrive/My Drive/1_Rendu/20241115/CleanDataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.read_csv('../Data/Datapreprocessing/Complete/CompleteDataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupération de 'TotalResponseTimeCategory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catégorisation du temps de réponse en catégorielle\n",
    "df_complete['ResponseTimeCategory']=0\n",
    "inf=[150, 180, 210, 240, 270, 300, 330, 360, 390, 450, 540]\n",
    "sup=[180, 210, 240, 270, 300, 330, 360, 390, 450, 540, 630]\n",
    "\n",
    "j=0\n",
    "for i in range(0,11):\n",
    "  j=j+1\n",
    "  df_complete.loc[(df_complete.TotalResponseTime>inf[i]) & (df_complete.TotalResponseTime<=sup[i]), 'ResponseTimeCategory']=j\n",
    "\n",
    "df_complete.loc[(df_complete.TotalResponseTime>=630), 'ResponseTimeCategory']=11\n",
    "\n",
    "del inf,sup,j,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete['HCat']='H'\n",
    "df_complete.loc[(df_complete.HourOfCall>=2) & (df_complete.HourOfCall<=6),'HCat']='H26'\n",
    "df_complete.loc[(df_complete.HourOfCall>=11) & (df_complete.HourOfCall<=17),'HCat']='H1117'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour notre étude la variable cible 'TotalResponseTime_BC' en continue ou 'ResponseTimeCategory' en discrèt.\n",
    "\n",
    "Pour la prédiction nous garderons 'HCat','DetailedIncidentGroup', 'PropertyCategory','BoroughCode','Station_Code' qui sont des variables qualitatives possédant respectivement  3 modalités, 27 modalités, 9 modalités, 33 modalités, 102 modalités, et 'distance' qui est une variable quantitative.\n",
    "\n",
    "Lors de la binarisation des données (pour faire fonctionner des algorithme de prédiction) nous avons donc un dataset de 3+27+9+33+102 = 174 variables. Ce nombres important de variables est génant car il va augmenter fortement le temps de calcul des différents algorithme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place de ACM sur le jeu de données complet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Présentation** une Analyse en Correspondance Multiple (ACM) est une méthode statistique qui permet d'explorer et de visualiser des données qualitatives.\n",
    "\n",
    "**Objectifs :**\n",
    "- Découvrir des liens cachés : Elle montre si certaines réponses à des questions sont souvent associées ensemble.\n",
    "- Réduire la complexité : Elle transforme un tableau complexe en un graphique plus simple, où les points représentent les personnes et les groupes de réponses similaires sont proches les uns des autres.\n",
    "- Visualiser les données: Tu permet de voir d'un coup d'œil les grandes tendances dans les données.\n",
    "\n",
    "L'ACM est accéssible directement en Python à l'aide du package fanalysis (lien pour explication : https://github.com/OlivierGarciaDev/fanalysis/blob/master/doc/mca_tutorial.ipynb).\n",
    "\n",
    "**Principe :** ACP (quantitative) -> AFC (2 qualitatives) -> ACM (plusieurs qualitatives)\n",
    "ACP sur tableau de contingence avec une métrique discrète du khi²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO6KeCxx9w2t"
   },
   "source": [
    "#### Approche visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c04dDYZs74iF"
   },
   "source": [
    "Dans une approche \"datamining\", l'ACM vise à décrire un jeu de données\n",
    "\n",
    "Cette première étape peu être faite dans la datavisualisation (a savoir notebook 2)\n",
    "\n",
    "Notre DataFrame contient, à l'heure actuelle, les colonnes suivantes :\n",
    "- 'TotalResponseTime_BC' ou 'ResponseTimeCategory' la variable cible -> considérée comme variable suplémentaire.\n",
    "- 'HCat', 'DetailedIncidentGroup', 'PropertyCategory', 'BoroughCode', 'Station_Code' nos variables descriptives (catégorie d'heure, détail d'incident, type de propriété, code arrondissement et code station).\n",
    "- 'distance' notre variable quantitative que nous traiterons en variable suplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variables actives\n",
    "data_active = df_complete[['HCat', 'PropertyCategory','BoroughCode','Station_Code']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'objet MCA et ajustement du modèle\n",
    "mca = MCA() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la MCA à data_active\n",
    "\n",
    "# Création d'une matrice (tableau de tableau) contenant la description de chaque individus\n",
    "X = data_active.values\n",
    "\n",
    "# Entrainement de la MCA sur X\n",
    "mca.fit(X)\n",
    "\n",
    "del X\n",
    "del data_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des valeurs propres**\n",
    "\n",
    "L'attribut my_mca.eig_ contient :\n",
    "\n",
    "- en 1ère ligne : les valeurs propres en valeur absolue\n",
    "- en 2ème ligne : les valeurs propres en pourcentage de la variance totale\n",
    "- en 3ème ligne : les valeurs propres en pourcentage cumulé de la variance totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.42426287, 1.39180018, 1.38992403, 1.37492961, 1.36902312,\n",
       "       1.35556591, 1.34453241, 1.33962985, 1.32969187, 1.31844932])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage des 10 premières valeurs propres en pourcentage \n",
    "mca.eig_[1,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tableau des valeurs valeurs propres nous indique que :\n",
    "- Le première axe contidendra 13% des informations contenues dans le jeu de données\n",
    "- Le deuxième axe contiendra 12% des informations contenues dans le jeu de données \n",
    "- et ainsi de suite\n",
    "\n",
    "Pour choisir le nombre d'axe à garder, on regarde l'inertie totale expliquée (somme des valeurs propres). Pour notre jeux de données on souhaite garder 95% de l'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "arg_max =np.argmax(mca.eig_[2,:]>=95)\n",
    "print(arg_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour conserver 95% des informations totales il faut conserver 133 dimensions (correspondant à 133 colonnes : col_active + 'distance') soit 76%. Ce qui conrrespond à une diminution de 24% de la taille des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyqTMSVtoIP3"
   },
   "source": [
    "Création d'une nouvelle ACM conservant 95% des informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la nouvelle ACM\n",
    "mca = MCA(arg_max+1,stats=False)\n",
    "\n",
    "del arg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MCA(n_components=np.int64(110), stats=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MCA<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MCA(n_components=np.int64(110), stats=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MCA(n_components=np.int64(110), stats=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Application de de la MCA à df_train\n",
    "mca.fit(df_complete[['HCat', 'PropertyCategory','BoroughCode','Station_Code']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93191863, -1.86715895,  1.54488929, ..., -0.02078472,\n",
       "        -0.00450026, -0.00364009],\n",
       "       [ 0.93191863, -1.86715895,  1.54488929, ..., -0.02078472,\n",
       "        -0.00450026, -0.00364009],\n",
       "       [ 0.93806702, -1.85681744,  1.53574448, ..., -0.02098635,\n",
       "        -0.00504444, -0.00370071],\n",
       "       ...,\n",
       "       [ 0.34167795, -1.31322527,  0.93865301, ..., -0.01715964,\n",
       "         0.00482759, -0.00384971],\n",
       "       [ 0.34167795, -1.31322527,  0.93865301, ..., -0.01715964,\n",
       "         0.00482759, -0.00384971],\n",
       "       [ 0.33001641, -1.29928115,  0.93497946, ..., -0.01773919,\n",
       "         0.00529323, -0.00408483]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = mca.transform(df_complete.loc[:50000,['HCat', 'PropertyCategory','BoroughCode','Station_Code']].values)\n",
    "X1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 143)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfo_temp(mca,X):\n",
    "    '''\n",
    "    Transformation grace à la MCA du dataFrame par jeu de 50 000 lignes\n",
    "\n",
    "    Args :\n",
    "        mca -> transformateur de MCA\n",
    "        X dataFrame\n",
    "    '''\n",
    "    df_mca = pd.DataFrame()\n",
    "    for i in range(0,(X.shape[0]//50000 + 1)):\n",
    "\n",
    "        print(i)\n",
    "    \n",
    "        # Application de de la MCA à df\n",
    "        X = mca.transform(X.iloc[i*50000+1:(i+1)*50000,:].values)[:,:mca.n_components_]\n",
    "\n",
    "        # Transformation en dataFrame\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "        # Concatenation\n",
    "        df_mca = pd.concat([df_mca,X],axis=0)\n",
    "\n",
    "    return df_mca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.023809523809522"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(168-131)/168*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "X_mca = transfo_temp(mca,df_complete[['HCat', 'PropertyCategory','BoroughCode','Station_Code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.931919</td>\n",
       "      <td>-1.867159</td>\n",
       "      <td>1.544889</td>\n",
       "      <td>0.327772</td>\n",
       "      <td>-0.686327</td>\n",
       "      <td>0.709595</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>-0.126618</td>\n",
       "      <td>-1.630982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044393</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>-0.003640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938067</td>\n",
       "      <td>-1.856817</td>\n",
       "      <td>1.535744</td>\n",
       "      <td>0.298214</td>\n",
       "      <td>-0.713308</td>\n",
       "      <td>0.715453</td>\n",
       "      <td>-0.978410</td>\n",
       "      <td>0.716468</td>\n",
       "      <td>-0.136345</td>\n",
       "      <td>-1.640478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047070</td>\n",
       "      <td>0.053224</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>-0.032338</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.003878</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>-0.005044</td>\n",
       "      <td>-0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.931919</td>\n",
       "      <td>-1.867159</td>\n",
       "      <td>1.544889</td>\n",
       "      <td>0.327772</td>\n",
       "      <td>-0.686327</td>\n",
       "      <td>0.709595</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>-0.126618</td>\n",
       "      <td>-1.630982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044393</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>-0.003640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.949729</td>\n",
       "      <td>-1.870762</td>\n",
       "      <td>1.539418</td>\n",
       "      <td>0.294337</td>\n",
       "      <td>-0.706819</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>-0.973636</td>\n",
       "      <td>0.707017</td>\n",
       "      <td>-0.130866</td>\n",
       "      <td>-1.647150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>0.052872</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>-0.032867</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>-0.020407</td>\n",
       "      <td>-0.005510</td>\n",
       "      <td>-0.003466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943580</td>\n",
       "      <td>-1.881103</td>\n",
       "      <td>1.548563</td>\n",
       "      <td>0.323896</td>\n",
       "      <td>-0.679838</td>\n",
       "      <td>0.708103</td>\n",
       "      <td>-1.019357</td>\n",
       "      <td>0.686898</td>\n",
       "      <td>-0.121139</td>\n",
       "      <td>-1.637654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044498</td>\n",
       "      <td>0.052431</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>-0.005965</td>\n",
       "      <td>-0.005752</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>-0.003405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.931919 -1.867159  1.544889  0.327772 -0.686327  0.709595 -1.024131   \n",
       "1  0.938067 -1.856817  1.535744  0.298214 -0.713308  0.715453 -0.978410   \n",
       "2  0.931919 -1.867159  1.544889  0.327772 -0.686327  0.709595 -1.024131   \n",
       "3  0.949729 -1.870762  1.539418  0.294337 -0.706819  0.713961 -0.973636   \n",
       "4  0.943580 -1.881103  1.548563  0.323896 -0.679838  0.708103 -1.019357   \n",
       "\n",
       "        7         8         9    ...       133       134       135       136  \\\n",
       "0  0.696349 -0.126618 -1.630982  ... -0.044393  0.052782  0.012724  0.021583   \n",
       "1  0.716468 -0.136345 -1.640478  ... -0.047070  0.053224  0.012258  0.023235   \n",
       "2  0.696349 -0.126618 -1.630982  ... -0.044393  0.052782  0.012724  0.021583   \n",
       "3  0.707017 -0.130866 -1.647150  ... -0.047175  0.052872  0.012449  0.023755   \n",
       "4  0.686898 -0.121139 -1.637654  ... -0.044498  0.052431  0.012916  0.022104   \n",
       "\n",
       "        137       138       139       140       141       142  \n",
       "0 -0.033837 -0.006488 -0.005117 -0.020785 -0.004500 -0.003640  \n",
       "1 -0.032338 -0.006752 -0.003878 -0.020986 -0.005044 -0.003701  \n",
       "2 -0.033837 -0.006488 -0.005117 -0.020785 -0.004500 -0.003640  \n",
       "3 -0.032867 -0.006228 -0.004513 -0.020407 -0.005510 -0.003466  \n",
       "4 -0.034365 -0.005965 -0.005752 -0.020205 -0.004966 -0.003405  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_col(X_mca,X):\n",
    "    X_mca = pd.DataFrame(np.hstack([X_mca.value, X.loc[:,['distStd']].values]))\n",
    "    X_mca = pd.DataFrame(np.hstack([X.loc[:,['TotalResponseTime_BC']].values,X_mca.value]))\n",
    "    X_mca = pd.DataFrame(np.hstack([X.loc[:,['ResponseTimeCategory']].values,X_mca.value]))\n",
    "    X_mca = X_mca.rename(columns={X_mca.columns[0]: 'TotalResponseTime_BC'})\n",
    "    X_mca = X_mca.rename(columns={X_mca.columns[1]: 'ResponseTimeCategory'})\n",
    "    X_mca = X_mca.rename(columns={X_mca.columns[-1]: 'distStd'})\n",
    "    return X_mca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_col2(X_mca,X):\n",
    "    # Ajouter la colonne 'distStd'\n",
    "    X_mca['distance'] = X['distance']\n",
    "\n",
    "    # Ajouter la colonne 'TotalResponseTime_BC'\n",
    "    X_mca.insert(0, 'TotalResponseTime_BC', X['TotalResponseTime_BC']) \n",
    "\n",
    "    # Ajouter la colonne 'ResponseTimeCategory'\n",
    "    X_mca.insert(1, 'ResponseTimeCategory', X['ResponseTimeCategory'])\n",
    "\n",
    "    return X_mca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X_mca.copy()\n",
    "X2['distance']=df_complete['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ajout_col2(X_mca,df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalResponseTime_BC</th>\n",
       "      <th>ResponseTimeCategory</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.381590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931919</td>\n",
       "      <td>-1.867159</td>\n",
       "      <td>1.544889</td>\n",
       "      <td>0.327772</td>\n",
       "      <td>-0.686327</td>\n",
       "      <td>0.709595</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>-0.003640</td>\n",
       "      <td>3770.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.327167</td>\n",
       "      <td>11</td>\n",
       "      <td>0.938067</td>\n",
       "      <td>-1.856817</td>\n",
       "      <td>1.535744</td>\n",
       "      <td>0.298214</td>\n",
       "      <td>-0.713308</td>\n",
       "      <td>0.715453</td>\n",
       "      <td>-0.978410</td>\n",
       "      <td>0.716468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053224</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.023235</td>\n",
       "      <td>-0.032338</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.003878</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>-0.005044</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>3781.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.787931</td>\n",
       "      <td>10</td>\n",
       "      <td>0.931919</td>\n",
       "      <td>-1.867159</td>\n",
       "      <td>1.544889</td>\n",
       "      <td>0.327772</td>\n",
       "      <td>-0.686327</td>\n",
       "      <td>0.709595</td>\n",
       "      <td>-1.024131</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.012724</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>-0.006488</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>-0.003640</td>\n",
       "      <td>3785.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.631018</td>\n",
       "      <td>9</td>\n",
       "      <td>0.949729</td>\n",
       "      <td>-1.870762</td>\n",
       "      <td>1.539418</td>\n",
       "      <td>0.294337</td>\n",
       "      <td>-0.706819</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>-0.973636</td>\n",
       "      <td>0.707017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052872</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>-0.032867</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>-0.004513</td>\n",
       "      <td>-0.020407</td>\n",
       "      <td>-0.005510</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>3802.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.287106</td>\n",
       "      <td>10</td>\n",
       "      <td>0.943580</td>\n",
       "      <td>-1.881103</td>\n",
       "      <td>1.548563</td>\n",
       "      <td>0.323896</td>\n",
       "      <td>-0.679838</td>\n",
       "      <td>0.708103</td>\n",
       "      <td>-1.019357</td>\n",
       "      <td>0.686898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052431</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>-0.005965</td>\n",
       "      <td>-0.005752</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>-0.003405</td>\n",
       "      <td>3757.621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TotalResponseTime_BC  ResponseTimeCategory         0         1         2  \\\n",
       "0              2.381590                     0  0.931919 -1.867159  1.544889   \n",
       "1             40.327167                    11  0.938067 -1.856817  1.535744   \n",
       "2             34.787931                    10  0.931919 -1.867159  1.544889   \n",
       "3             33.631018                     9  0.949729 -1.870762  1.539418   \n",
       "4             34.287106                    10  0.943580 -1.881103  1.548563   \n",
       "\n",
       "          3         4         5         6         7  ...       134       135  \\\n",
       "0  0.327772 -0.686327  0.709595 -1.024131  0.696349  ...  0.052782  0.012724   \n",
       "1  0.298214 -0.713308  0.715453 -0.978410  0.716468  ...  0.053224  0.012258   \n",
       "2  0.327772 -0.686327  0.709595 -1.024131  0.696349  ...  0.052782  0.012724   \n",
       "3  0.294337 -0.706819  0.713961 -0.973636  0.707017  ...  0.052872  0.012449   \n",
       "4  0.323896 -0.679838  0.708103 -1.019357  0.686898  ...  0.052431  0.012916   \n",
       "\n",
       "        136       137       138       139       140       141       142  \\\n",
       "0  0.021583 -0.033837 -0.006488 -0.005117 -0.020785 -0.004500 -0.003640   \n",
       "1  0.023235 -0.032338 -0.006752 -0.003878 -0.020986 -0.005044 -0.003701   \n",
       "2  0.021583 -0.033837 -0.006488 -0.005117 -0.020785 -0.004500 -0.003640   \n",
       "3  0.023755 -0.032867 -0.006228 -0.004513 -0.020407 -0.005510 -0.003466   \n",
       "4  0.022104 -0.034365 -0.005965 -0.005752 -0.020205 -0.004966 -0.003405   \n",
       "\n",
       "   distance  \n",
       "0  3770.970  \n",
       "1  3781.096  \n",
       "2  3785.636  \n",
       "3  3802.989  \n",
       "4  3757.621  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise en place de l'ACM sur le jeu d'entrainement, de validation et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfo_mca(col_desc_quali,df_train,df_validation=None,df_test=None):\n",
    "    \"\"\"\n",
    "    Appliquer une réduction de dimension par ACM en conservant 95% des informations\n",
    "\n",
    "    Args:\n",
    "        col_desc_quali -> list : nom des variables qualitatives\n",
    "        df_train, df_validation, df_test -> dataFrame d'entrainement, de validation et de test. \n",
    "    \"\"\"\n",
    "\n",
    "    data_desc = df_train[col_desc_quali]\n",
    "\n",
    "    # Création de l'objet MCA et ajustement du modèle\n",
    "    mca = MCA(row_labels=data_desc.index.values, var_labels=data_desc.columns.values) \n",
    "\n",
    "    # Création d'une matrice (tableau de tableau) contenant la description de chaque individus\n",
    "    X = data_desc.values\n",
    "\n",
    "    # Entrainement de la MCA sur X\n",
    "    mca.fit(X)\n",
    "\n",
    "    # Récupération de l'indice pour 95% des informations\n",
    "    arg_max =np.argmax(mca.eig_[2,:]>=95)\n",
    "\n",
    "    # Création de la nouvelle ACM\n",
    "    mca = MCA(n_components=arg_max+1,row_labels=data_desc.index.values, var_labels=data_desc.columns.values)\n",
    "\n",
    "    # Application de de la MCA à df_train\n",
    "    df_train_mca = mca.fit_transform(df_train[col_desc_quali].values)\n",
    "\n",
    "    # Transformation en dataFrame\n",
    "    df_train_mca = pd.DataFrame(df_train_mca)\n",
    "\n",
    "\n",
    "    # Ajout de la variable 'distance'\n",
    "    df_train_transfo = pd.concat([df_train_mca,df_train['distance']],axis=1) \n",
    "\n",
    "    # Application de de la MCA à df_validation \n",
    "    df_validation_mca = mca.transform(df_validation[col_desc_quali].values)\n",
    "\n",
    "    # Transformation en dataFrame\n",
    "    df_validation_mca = pd.DataFrame(df_validation_mca)\n",
    "\n",
    "    # Ajout de la variable 'distance'\n",
    "    df_validation_transfo = pd.concat([df_validation_mca,df_validation['distance']],axis=1) \n",
    "\n",
    "    # Application de de la MCA à df_test\n",
    "    df_test_mca = mca.transform(df_test[col_desc_quali].values)\n",
    "\n",
    "    # Transformation en dataFrame\n",
    "    df_test_mca = pd.DataFrame(df_test_mca)\n",
    "\n",
    "    # Ajout de la variable 'distance'\n",
    "    df_test_transfo = pd.concat([df_test_mca,df_train['distance']],axis=1) \n",
    "    \n",
    "    return df_train_transfo,df_validation_transfo,df_test_transfo\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfo_mca(col_desc_quali,df_train):\n",
    "    \"\"\"\n",
    "    Appliquer une réduction de dimension par ACM en conservant 95% des informations\n",
    "\n",
    "    Args:\n",
    "        col_desc_quali -> list : nom des variables qualitatives\n",
    "        df_train, df_validation, df_test -> dataFrame d'entrainement, de validation et de test. \n",
    "    \"\"\"\n",
    "\n",
    "    data_desc = df_train[col_desc_quali]\n",
    "\n",
    "    # Création de l'objet MCA et ajustement du modèle\n",
    "    mca = MCA(row_labels=data_desc.index.values, var_labels=data_desc.columns.values) \n",
    "\n",
    "    # Création d'une matrice (tableau de tableau) contenant la description de chaque individus\n",
    "    X = data_desc.values\n",
    "\n",
    "    # Entrainement de la MCA sur X\n",
    "    mca.fit(X)\n",
    "\n",
    "    # Récupération de l'indice pour 95% des informations\n",
    "    arg_max =np.argmax(mca.eig_[2,:]>=95)\n",
    "\n",
    "    # Création de la nouvelle ACM\n",
    "    mca = MCA(n_components=arg_max+1,row_labels=data_desc.index.values, var_labels=data_desc.columns.values)\n",
    "\n",
    "    # Entrainement du modèle\n",
    "    mca.fit(df_train[col_desc_quali].values)\n",
    "\n",
    "    # Application de de la MCA à df_train\n",
    "    X = mca.transform(df_train.loc[:50000,col_desc_quali].values)[:,:arg_max+1]\n",
    "\n",
    "    # Transformation en dataFrame\n",
    "    df_train_transfo = pd.DataFrame(X)\n",
    "\n",
    "    for i in range(1,(df_train.shape[0]//50000 + 1)):\n",
    "    \n",
    "\n",
    "        # Application de de la MCA à df_train\n",
    "        X = mca.transform(df_train.loc[i*50000+1:(i+1)*50000,col_desc_quali].values)[:,:arg_max+1]\n",
    "\n",
    "        # Transformation en dataFrame\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "        # Concatenation\n",
    "        df_train_transfo = pd.concat([df_train_transfo,X],axis=0)\n",
    "\n",
    "    # Ajout de la variable 'distance'\n",
    "    # Concaténation en utilisant numpy.hstack\n",
    "    df_train_transfo = pd.DataFrame(np.hstack([df_train_transfo.values, df_train.loc[:,['distance']].values]))\n",
    "    df_train_transfo = df_train_transfo.rename(columns={df_train_transfo.columns[-1]: 'distance'})\n",
    "\n",
    "    return df_train_transfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (100000, 63)\n",
      "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
      "       ...\n",
      "       49989, 49990, 49991, 49992, 49993, 49994, 49995, 49996, 49997, 49998],\n",
      "      dtype='int64', length=100000)\n",
      "base (100000, 1)\n",
      "RangeIndex(start=0, stop=100000, step=1)\n"
     ]
    }
   ],
   "source": [
    "df_train_transfo=transfo_mca(['HCat','DetailedIncidentGroup', 'PropertyCategory','BoroughCode','Station_Code'],\n",
    "                                                                   df_complete.iloc[:100000,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         0,          1,          2,          3,          4,          5,\n",
       "                6,          7,          8,          9,         10,         11,\n",
       "               12,         13,         14,         15,         16,         17,\n",
       "               18,         19,         20,         21,         22,         23,\n",
       "               24,         25,         26,         27,         28,         29,\n",
       "               30,         31,         32,         33,         34,         35,\n",
       "               36,         37,         38,         39,         40,         41,\n",
       "               42,         43,         44,         45,         46,         47,\n",
       "               48,         49,         50,         51,         52,         53,\n",
       "               54,         55,         56,         57,         58,         59,\n",
       "               60,         61,         62, 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_transfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement_model(X):\n",
    "    '''\n",
    "    Construction d'une MCA pour garder 95% de l'information du dataFrame\n",
    "\n",
    "    Arg : X -> dataFrame\n",
    "    '''\n",
    "    # Création de l'objet MCA et ajustement du modèle\n",
    "    mca = MCA() \n",
    "\n",
    "    # Création d'une matrice (tableau de tableau) contenant la description de chaque individus\n",
    "    X = X.values\n",
    "\n",
    "    # Entrainement de la MCA sur X\n",
    "    mca.fit(X)\n",
    "\n",
    "    # Récupération de l'indice pour 95% des informations\n",
    "    arg_max =np.argmax(mca.eig_[2,:]>=95)\n",
    "\n",
    "    # Création de la nouvelle ACM\n",
    "    mca = MCA(n_components=arg_max+1,stats=False)\n",
    "\n",
    "    # Entrainement du modèle\n",
    "    mca.fit(X)\n",
    "\n",
    "    return mca\n",
    "\n",
    "def transfo_temp(mca,X):\n",
    "    '''\n",
    "    Transformation grace à la MCA du dataFrame par jeu de 50 000 lignes\n",
    "\n",
    "    Args :\n",
    "        mca -> transformateur de MCA\n",
    "        X dataFrame\n",
    "    '''\n",
    "    df_mca = pd.DataFrame()\n",
    "    for i in range(0,(X.shape[0]//50000 + 1)):\n",
    "    \n",
    "        # Application de de la MCA à df\n",
    "        X = mca.transform(X.iloc[i*50000+1:(i+1)*50000,:].values)[:,:mca.n_components_]\n",
    "\n",
    "        # Transformation en dataFrame\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "        # Concatenation\n",
    "        df_mca = pd.concat([df_mca,X],axis=0)\n",
    "\n",
    "    return df_mca\n",
    "\n",
    "def transfo_mca(col_desc_quali,X_train,X_val,X_test):\n",
    "    '''\n",
    "    Appliquer une réduction de dimension par ACM en conservant 95% des informations\n",
    "\n",
    "    Args:\n",
    "        col_desc_quali -> list : nom des variables qualitatives\n",
    "        df_train, df_validation, df_test -> dataFrame d'entrainement, de validation et de test. \n",
    "    '''\n",
    "    # Entrainement du modèle\n",
    "    mca = entrainement_model(X_train.loc[:,col_desc_quali])\n",
    "\n",
    "    # Transformation de X_train\n",
    "    X_train_mca = transfo_temp(mca,X_train.loc[:,col_desc_quali])\n",
    "    X_train_mca = pd.DataFrame(np.hstack([X_train.values, X_train.loc[:,['distance']].values]))\n",
    "    X_train_mca = X_train_mca.rename(columns={X_train_mca.columns[-1]: 'distance'})\n",
    "    \n",
    "\n",
    "    # Transformation de X_validation\n",
    "    X_val_mca = transfo_temp(mca,X_val.loc[:,col_desc_quali])\n",
    "    X_val_mca = pd.DataFrame(np.hstack([X_val.values, X_val.loc[:,['distance']].values]))\n",
    "    X_val_mca = X_val_mca.rename(columns={X_val_mca.columns[-1]: 'distance'})\n",
    "\n",
    "    # Transformation de X_train\n",
    "    X_test_mca = transfo_temp(mca,X_test.loc[:,col_desc_quali])\n",
    "    X_test_mca = pd.DataFrame(np.hstack([X_train.values, X_test.loc[:,['distance']].values]))\n",
    "    X_test_mca = X_test_mca.rename(columns={X_test_mca.columns[-1]: 'distance'})\n",
    "\n",
    "    return X_train_mca,X_val_mca,X_test_mca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IncidentNumber', 'TurnoutTime', 'TravelTime', 'TotalResponseTime',\n",
       "       'TotalResponseTime_BC', 'ResponseTimeCategory', 'DateOfCall', 'CalYear',\n",
       "       'TimeOfCall', 'HourOfCall', 'DayOfWeek', 'Month', 'IncidentGroup',\n",
       "       'Incident_Type', 'PropertyCategory', 'HighPropertyType', 'BoroughCode',\n",
       "       'BoroughName', 'WardCode', 'WardName', 'Station_Code', 'Station_Name',\n",
       "       'distance', 'Latitude', 'Longitude', 'IncGeo_Rounded', 'Lat_station',\n",
       "       'Long_station', 'HCat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.iloc[:100000,:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1,df2,df3=transfo_mca(['HCat','PropertyCategory','BoroughCode','Station_Code'],\n",
    "                                                                   df_complete.iloc[:100000,:],\n",
    "                                                                   df_complete.iloc[:100000,:],\n",
    "                                                                   df_complete.iloc[:100000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_complete.loc[1000000:1050000,['HCat','DetailedIncidentGroup', 'PropertyCategory','BoroughCode','Station_Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PpFe80XIUPhw",
    "jaiGyQtEoVEl",
    "w3xkZdvjN-fC"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
